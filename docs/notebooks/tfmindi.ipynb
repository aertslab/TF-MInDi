{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6678272f",
   "metadata": {},
   "source": [
    "# TF-MInDi on Mouse Cortex\n",
    "\n",
    "To illustrate how TF-MInDi works we calculated contribution scores for the top 2000 most specific regions for every cell type of the mouse cortex using \n",
    "`CREsted`'s DeepBICCN2 model (see [the model](https://crested.readthedocs.io/en/latest/models/BICCN/deepbiccn2.html) and [specific contribution scores](https://crested.readthedocs.io/en/latest/api/tools/_autosummary/crested.tl.contribution_scores_specific.html) calculation).\n",
    "\n",
    "That function should give you a directory of contribution scores per cell type and one hot encoded regions per cell type (.npz).  \n",
    "We used CREsted, but you can use any model and input x output interpretation score calculation methods (such as tangermeme), as long as they are converted to the expected numpy array shape.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f605759",
   "metadata": {},
   "source": [
    "## Fetching motif collections and annotations\n",
    "\n",
    "On top of the contribution scores and sequences, we'll need motif collections to calculate similarity scores with the extracted seqlets.  \n",
    "TF-MInDi provides functionality to fetch and load some of the default SCENIC+ motif databases.  \n",
    "We can also fetch some motif annotations and motif-to-dbd mappings to visualize the seqlets later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab0db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfmindi as tm\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch collection and annotations\n",
    "motif_collection_dir = tmotif_collection_dir = tm.fetch_motif_collection()\n",
    "motif_annotations_file = tm.fetch_motif_annotations()\n",
    "\n",
    "# to speed up all analyses, we can choose to only load a sampled subset of motifs. We have selected some and stored those names in a .txt file.\n",
    "DATA_DIR = \"../../../../data/tfmindi/\"\n",
    "motif_samples_path = DATA_DIR + \"sampled_motifs.txt\"\n",
    "with open(motif_samples_path) as f:\n",
    "    motif_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# load them as dictionary of PPM matrices\n",
    "motif_collection = tm.load_motif_collection(motif_collection_dir, motif_names=motif_names)\n",
    "motif_annotations = tm.load_motif_annotations(motif_annotations_file)\n",
    "\n",
    "# load motif to dna-binding domain (DBD) mapping\n",
    "motif_to_db = tm.load_motif_to_dbd(motif_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5289005",
   "metadata": {},
   "source": [
    "## Extracting seqlets using tangermeme\n",
    "\n",
    "We use `tangermeme` to extract seqlets (spans of nucleotides with high importance scores) from our nucleotide level contribution scores per cell type.  \n",
    "We use the `tfmindi.pp.extract_seqlets` for this, which wraps `tangermeme`s [recursive_seqlets](https://tangermeme.readthedocs.io/en/latest/tutorials/Tutorial_A4_Seqlets.html#Recursive-Seqlets) functionality.  \n",
    "The resulting seqlets will be scaled to a range of [-1,1] and sign corrected so the average contribution values are always positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:21<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract_seqlets expects the inputs to be in shape (n, region_width, 4), so we concatenate the cell type specific contributions\n",
    "CONTRIB_FOLDER = DATA_DIR + \"modisco_results_ft_2000/\"\n",
    "\n",
    "contrib_list = []\n",
    "oh_list = []\n",
    "classes_list = []\n",
    "\n",
    "class_names = [\n",
    "    re.match(r\"(.+?)_oh\\.npz$\", f).group(1)  # type: ignore\n",
    "    for f in os.listdir(CONTRIB_FOLDER)\n",
    "    if f.endswith(\"_oh.npz\")\n",
    "]\n",
    "\n",
    "for i, c in enumerate(tqdm(class_names)):\n",
    "    contrib_list.append(np.load(os.path.join(CONTRIB_FOLDER, f\"{c}_contrib.npz\"))[\"arr_0\"])\n",
    "    oh_list.append(np.load(os.path.join(CONTRIB_FOLDER, f\"{c}_oh.npz\"))[\"arr_0\"])\n",
    "    classes_list.append(np.repeat(c, oh_list[i].shape[0]))\n",
    "\n",
    "oh = np.concatenate(oh_list)\n",
    "contrib = np.concatenate(contrib_list)\n",
    "classes = np.concatenate(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84c5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing seqlets: 100%|██████████| 1007193/1007193 [01:30<00:00, 11160.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract seqlets from the contributions and one-hot encoded sequences\n",
    "seqlets_df, seqlets_matrices = tm.pp.extract_seqlets(contrib=contrib, oh=oh, threshold=0.05, additional_flanks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d901862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_idx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>attribution</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13895</td>\n",
       "      <td>1096</td>\n",
       "      <td>1125</td>\n",
       "      <td>45.111572</td>\n",
       "      <td>4.839551e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12255</td>\n",
       "      <td>1020</td>\n",
       "      <td>1043</td>\n",
       "      <td>-34.561593</td>\n",
       "      <td>1.637069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13577</td>\n",
       "      <td>1067</td>\n",
       "      <td>1097</td>\n",
       "      <td>44.328660</td>\n",
       "      <td>3.006946e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_idx  start   end  attribution       p-value\n",
       "0        13895   1096  1125    45.111572  4.839551e-11\n",
       "1        12255   1020  1043   -34.561593  1.637069e-07\n",
       "2        13577   1067  1097    44.328660  3.006946e-07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlets_df.head(3)  # information on seqlet position and significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e17b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlets_matrices[0].shape  # seqlets_matrices is a list with len(seqlets), that contains the scaled matrix per seqlet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8a166",
   "metadata": {},
   "source": [
    "## Calculating motif similarity\n",
    "\n",
    "Next, we calculate similarity scores between the extracted seqlets and the SCENIC+ motif collection by using `memelite`'s TomTom implementation.  \n",
    "The resulting similarity matrix will be log-transformed and negated before performing clustering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be2a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Allocation failed (probably too large).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sim_matrix = \u001b[43mtm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_motif_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqlets_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmotif_collection\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/TF-MInDi/src/tfmindi/pp/seqlets.py:103\u001b[39m, in \u001b[36mcalculate_motif_similarity\u001b[39m\u001b[34m(seqlets, known_motifs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(known_motifs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    102\u001b[39m     known_motifs = \u001b[38;5;28mlist\u001b[39m(known_motifs.values())\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m sim, _, _, _, _ = \u001b[43mtomtom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseqlets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknown_motifs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m l_sim = np.nan_to_num(-np.log10(sim + \u001b[32m1e-10\u001b[39m))\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Handle empty arrays\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/tfmindi/OeeCTRxT/docs/lib/python3.12/site-packages/memelite/tomtom.py:511\u001b[39m, in \u001b[36mtomtom\u001b[39m\u001b[34m(Qs, Ts, n_nearest, n_score_bins, n_median_bins, n_target_bins, n_cache, reverse_complement, n_jobs)\u001b[39m\n\u001b[32m    507\u001b[39m \trr_counts = numpy.ones_like(rr_inv)\n\u001b[32m    509\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m results = \u001b[43m_tomtom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrr_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrr_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m\t\u001b[49m\u001b[43mn_nearest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_score_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_median_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreverse_complement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_jobs != -\u001b[32m1\u001b[39m:\n\u001b[32m    516\u001b[39m \tnumba.set_num_threads(_n_jobs)\n",
      "\u001b[31mMemoryError\u001b[39m: Allocation failed (probably too large)."
     ]
    }
   ],
   "source": [
    "sim_matrix = tm.pp.calculate_motif_similarity(\n",
    "    seqlets_matrices, motif_collection, n_nearest=500\n",
    ")  # use n_nearest if you're running out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8493c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
